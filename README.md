# AutoLLM-Compressor

ä¸€ä¸ªå¯æ’æ‹”ã€å¯æ‰©å±•çš„å®Œå…¨æœ¬åœ°åŒ–è‡ªåŠ¨åŒ–å¤§æ¨¡å‹å‹ç¼©æ¡†æ¶ã€‚æ ¸å¿ƒè®¾è®¡ä¸ºâ€œæ³¨å†Œä¸­å¿ƒ + æœç´¢å¼•æ“ + æ‰§è¡Œå™¨ + è¯„ä¼°å™¨â€ï¼Œæ”¯æŒ Llama-2 ç­‰å¤§æ¨¡å‹åœ¨æœ¬åœ°ç¯å¢ƒä¸‹çš„è‡ªåŠ¨å‹ç¼©ä¸è¯„ä¼°ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

*   **å®Œå…¨æœ¬åœ°åŒ–**: æ”¯æŒåŠ è½½æœ¬åœ°æ¨¡å‹ï¼ˆå¦‚ Llama-2ï¼‰å’Œæœ¬åœ°æ•°æ®é›†ï¼ˆWikiText-2ï¼‰ï¼Œæ— éœ€è”ç½‘ï¼Œå®‰å…¨ç¨³å®šã€‚
*   **æ’ä»¶åŒ–æ¶æ„**: å‹ç¼©ç®—æ³•ï¼ˆå‰ªæã€é‡åŒ–ï¼‰é€šè¿‡è£…é¥°å™¨æ³¨å†Œï¼Œé›¶ä¾µå…¥æ‰©å±•ã€‚
*   **è‡ªåŠ¨æœç´¢**: å†…ç½® Grid Search è‡ªåŠ¨å¯»æ‰¾æœ€ä¼˜å‹ç¼©å‚æ•°ç»„åˆï¼ˆSparsity, Bits ç­‰ï¼‰ã€‚
*   **çœŸå®è¯„ä¼°**: åŸºäº PPL (Perplexity) çš„é—­ç¯è¯„ä¼°ï¼Œæ‹’ç»éšæœºæ•°æ®ç³Šå¼„ã€‚

## ğŸ“‚ é¡¹ç›®ç»“æ„è¯¦è§£

```text
AutoLLM-Compressor/
â”œâ”€â”€ core/                       # [æ ¸å¿ƒå¼•æ“]
â”‚   â”œâ”€â”€ compressor.py           # å‹ç¼©æ‰§è¡Œå™¨ï¼šè´Ÿè´£è°ƒç”¨å…·ä½“çš„å‹ç¼©ç®—æ³•ä¿®æ”¹æ¨¡å‹
â”‚   â”œâ”€â”€ engine.py               # æœç´¢å¼•æ“ï¼šå®ç° Grid Search ç­‰ç­–ç•¥ï¼Œå¯»æ‰¾æœ€ä½³é…ç½®
â”‚   â”œâ”€â”€ evaluator.py            # è¯„ä¼°å™¨ï¼šè®¡ç®—æ¨¡å‹çš„ PPL (å›°æƒ‘åº¦)
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ methods/                    # [ç®—æ³•ä»“åº“]
â”‚   â”œâ”€â”€ pruning/                # å‰ªæç®—æ³•
â”‚   â”‚   â”œâ”€â”€ random.py           # éšæœºå‰ªæ (Baseline)
â”‚   â”‚   â”œâ”€â”€ l2.py               # L2 ç»“æ„åŒ–å‰ªæ (Structured Pruning)
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ quantization/           # é‡åŒ–ç®—æ³•
â”‚   â”‚   â”œâ”€â”€ fp16.py             # FP16 åŠç²¾åº¦é‡åŒ– (æ˜¾å­˜å‡åŠ)
â”‚   â”‚   â”œâ”€â”€ int8_sq.py          # INT8-SQ æ¨¡æ‹Ÿé‡åŒ– (SmoothQuant æ€æƒ³)
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                 # ç®—æ³•åŸºç±»ï¼Œå®šä¹‰æ ‡å‡†æ¥å£
â”‚   â”œâ”€â”€ registry.py             # æ³¨å†Œä¸­å¿ƒï¼Œç®¡ç†æ‰€æœ‰å¯ç”¨ç®—æ³•
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ utils/                      # [å·¥å…·ç±»]
â”‚   â”œâ”€â”€ data_loader.py          # æ•°æ®åŠ è½½å™¨ï¼šè´Ÿè´£è¯»å–æœ¬åœ° WikiText-2 æ•°æ®
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ models/                     # [æ¨¡å‹å­˜æ”¾åŒº]
â”‚   â””â”€â”€ Llama-2-7b-hf/          # (éœ€è‡ªè¡Œä¸‹è½½) Llama-2 æ¨¡å‹æ–‡ä»¶
â”‚
â”œâ”€â”€ data/                       # [æ•°æ®å­˜æ”¾åŒº]
â”‚   â””â”€â”€ wikitext2/              # (éœ€è‡ªè¡Œä¸‹è½½) WikiText-2 æµ‹è¯•é›†
â”‚       â””â”€â”€ test.txt
â”‚
â”œâ”€â”€ scripts/                    # [è¾…åŠ©è„šæœ¬]
â”‚   â”œâ”€â”€ download_model.py       # ä» HuggingFace ä¸‹è½½æ¨¡å‹çš„è„šæœ¬
â”‚   â”œâ”€â”€ download_from_modelscope.py # ä» ModelScope (é­”å¡”) ä¸‹è½½æ¨¡å‹çš„è„šæœ¬
â”‚   â””â”€â”€ download_data.py        # ä¸‹è½½ WikiText-2 æ•°æ®é›†çš„è„šæœ¬
â”‚
â”œâ”€â”€ results/                    # [ç»“æœè¾“å‡º]
â”‚   â””â”€â”€ report_*.json           # æ¯æ¬¡è¿è¡Œçš„è¯¦ç»†å®éªŒæŠ¥å‘Š
â”‚
â”œâ”€â”€ main.py                     # [ä¸»å…¥å£] é¡¹ç›®å¯åŠ¨æ–‡ä»¶
â””â”€â”€ README.md                   # é¡¹ç›®æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡
```bash
# å®‰è£…ä¾èµ–
pip install torch transformers datasets modelscope
```

### 2. å‡†å¤‡æ¨¡å‹ä¸æ•°æ®
æœ¬é¡¹ç›®è®¾è®¡ä¸º**ç¦»çº¿è¿è¡Œ**ï¼Œå› æ­¤é¦–æ¬¡ä½¿ç”¨å‰éœ€è¦ä¸‹è½½èµ„æºï¼š

*   **ä¸‹è½½æ•°æ®**:
    ```bash
    python scripts/download_data.py
    ```
    è¿™ä¼šå°† WikiText-2 ä¸‹è½½åˆ° `data/wikitext2/test.txt`ã€‚

*   **ä¸‹è½½æ¨¡å‹ (ä»¥ Llama-2 ä¸ºä¾‹)**:
    ```bash
    # æ¨èï¼šä½¿ç”¨é­”å¡”ç¤¾åŒºä¸‹è½½ (é€Ÿåº¦å¿«ï¼Œæ— éœ€æƒé™)
    python scripts/download_from_modelscope.py
    ```
    è¿™ä¼šå°†æ¨¡å‹ä¸‹è½½åˆ° `models/Llama-2-7b-hf`ã€‚

### 3. è¿è¡Œé¡¹ç›®
èµ„æºå‡†å¤‡å¥½åï¼Œç›´æ¥è¿è¡Œä¸»ç¨‹åºå³å¯ï¼š

```bash
python main.py
```

ç¨‹åºä¼šè‡ªåŠ¨ï¼š
1.  åŠ è½½æœ¬åœ° Llama-2 æ¨¡å‹ã€‚
2.  åŠ è½½æœ¬åœ° WikiText-2 æ•°æ®ã€‚
3.  éå†æ‰€æœ‰å‹ç¼©ç®—æ³•ï¼ˆå‰ªæã€é‡åŒ–ï¼‰ã€‚
4.  è¯„ä¼°æ¯ç§é…ç½®çš„ PPLã€‚
5.  è¾“å‡ºæœ€ä½³é…ç½®å¹¶ä¿å­˜æŠ¥å‘Šåˆ° `results/` ç›®å½•ã€‚

### 4. è‡ªå®šä¹‰å‚æ•°
ä½ ä¹Ÿå¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°è°ƒæ•´å®éªŒè®¾ç½®ï¼š

```bash
python main.py --strategy grid --sparsity 0.5 --data_samples 20
```

*   `--model`: æŒ‡å®šæ¨¡å‹è·¯å¾„ (é»˜è®¤ `./models/Llama-2-7b-hf`)
*   `--strategy`: æœç´¢ç­–ç•¥ (`grid` æˆ– `random`)
*   `--sparsity`: ç›®æ ‡ç¨€ç–åº¦çº¦æŸ
*   `--data_samples`: ç”¨äºæ ¡å‡†/è¯„ä¼°çš„æ•°æ®æ ·æœ¬æ•°é‡ (å»ºè®® 10-20 ç”¨äºå¿«é€ŸéªŒè¯)

## ğŸ› ï¸ å¦‚ä½•å¯¼å…¥æ–°çš„å‹ç¼©æ–¹æ³•ï¼Ÿ

æœ¬é¡¹ç›®é‡‡ç”¨**æ³¨å†Œæœºåˆ¶**ï¼Œæ·»åŠ æ–°ç®—æ³•åªéœ€ç®€å•ä¸‰æ­¥ï¼š

### ç¬¬ä¸€æ­¥ï¼šæ–°å»ºæ–‡ä»¶
åœ¨ `methods/pruning/` æˆ– `methods/quantization/` ä¸‹æ–°å»ºä¸€ä¸ª Python æ–‡ä»¶ï¼ˆä¾‹å¦‚ `my_pruning.py`ï¼‰ã€‚

### ç¬¬äºŒæ­¥ï¼šç¼–å†™ç®—æ³•ç±»
ç»§æ‰¿ `BaseCompressionMethod` å¹¶ä½¿ç”¨ `@register_method` è£…é¥°å™¨ã€‚

```python
# methods/pruning/my_pruning.py

from methods.base import BaseCompressionMethod
from methods.registry import register_method
import torch

# 1. ä½¿ç”¨è£…é¥°å™¨æ³¨å†Œå”¯ä¸€åç§°
@register_method("my_custom_pruning")
class MyCustomPruning(BaseCompressionMethod):
    
    # 2. å®ç°æ ¸å¿ƒå‹ç¼©é€»è¾‘
    def apply(self, model, **kwargs):
        threshold = kwargs.get("threshold", 0.1)
        print(f"Applying My Pruning with threshold {threshold}...")
        # ... è¿™é‡Œå†™ä½ çš„å‰ªæä»£ç  ...
        return model
        
    # 3. å®šä¹‰æœç´¢ç©ºé—´ (ä¾›è‡ªåŠ¨æœç´¢ä½¿ç”¨)
    def get_info(self):
        return {
            "type": "pruning", 
            "search_space": {
                "threshold": [0.1, 0.3, 0.5] # æœç´¢å¼•æ“ä¼šå°è¯•è¿™äº›å€¼
            }
        }
```

### ç¬¬ä¸‰æ­¥ï¼šæ¿€æ´»
ç¡®ä¿ä½ çš„æ–°æ–‡ä»¶è¢«ç³»ç»Ÿå¯¼å…¥ã€‚ä½ å¯ä»¥ä¿®æ”¹ `main.py` åœ¨å¼€å¤´å¯¼å…¥å®ƒï¼Œæˆ–è€…ï¼ˆæ¨èï¼‰åœ¨ `methods/pruning/__init__.py` ä¸­æ·»åŠ ä¸€è¡Œå¯¼å…¥ï¼š

```python
# methods/pruning/__init__.py
from .random import RandomPruning
from .my_pruning import MyCustomPruning  # <--- æ–°å¢è¿™è¡Œ
```

**å®Œæˆï¼** ä¸‹æ¬¡è¿è¡Œ `python main.py` æ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å‘ç°å¹¶è¯„ä¼°ä½ çš„æ–°ç®—æ³•ã€‚

---
ç»´æŠ¤è€…ï¼šAutoLLM-Compressor é¡¹ç›®ç»„
