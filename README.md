# AutoLLM-Compressor (CompactMind)

ä¸€ä¸ªå®Œå…¨æœ¬åœ°åŒ–ã€å³æ’å³ç”¨çš„è‡ªåŠ¨åŒ–å¤§æ¨¡å‹å‹ç¼©æ¡†æ¶ã€‚æ ¸å¿ƒè®¾è®¡ä¸ºâ€œæ³¨å†Œä¸­å¿ƒ + æœç´¢å¼•æ“ + æ‰§è¡Œå™¨ + è¯„ä¼°å™¨â€ï¼Œæ”¯æŒ **é‡åŒ– (Quantization)**ã€**å‰ªæ (Pruning)** å’Œ **å†è®­ç»ƒ (Retraining)**ï¼Œå¹¶åˆ©ç”¨ **è´å¶æ–¯ä¼˜åŒ– (Bayesian Optimization)** è‡ªåŠ¨å¯»æ‰¾æœ€ä½³çš„æ··åˆå‹ç¼©ç­–ç•¥ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

*   **å®Œå…¨æœ¬åœ°åŒ–**: æ”¯æŒåŠ è½½æœ¬åœ°æ¨¡å‹ï¼ˆå¦‚ Llama-2ï¼‰å’Œæœ¬åœ°æ•°æ®é›†ï¼ˆWikiText-2ï¼‰ï¼Œæ— éœ€è”ç½‘ï¼Œå®‰å…¨ç¨³å®šã€‚
*   **æ··åˆå‹ç¼©ç®¡çº¿ (Hybrid Pipelines)**: è‡ªåŠ¨æœç´¢å•ä¸€æ–¹æ³•åŠç»„åˆæ–¹æ³•ï¼ˆä¾‹å¦‚ï¼šå‰ªæ -> å†è®­ç»ƒ -> é‡åŒ–ï¼‰ï¼Œå¯»æ‰¾æœ€ä¼˜è§£ã€‚
*   **è´å¶æ–¯ä¼˜åŒ–**: é›†æˆ **Optuna** æ¡†æ¶ï¼Œæ”¯æŒé«˜æ•ˆçš„è‡ªåŠ¨åŒ–å‚æ•°æœç´¢ã€‚
*   **è½»é‡çº§å†è®­ç»ƒ**: å†…ç½® Causal Language Modeling (CLM) å¾®è°ƒåŠŸèƒ½ï¼Œå¸®åŠ©æ¨¡å‹åœ¨å‰ªæåæ¢å¤æ€§èƒ½ã€‚
*   **å¯è§†åŒ–åˆ†æ**: è‡ªåŠ¨ç”Ÿæˆå¸•ç´¯æ‰˜å‰æ²¿å›¾ (Pareto Frontier) å’Œå¯äº¤äº’çš„æœç´¢ç©ºé—´åˆ†æå›¾è¡¨ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡
```bash
pip install -r requirements.txt
```

### 2. å‡†å¤‡æ¨¡å‹ä¸æ•°æ®
```bash
# ä¸‹è½½æ•°æ®é›† (WikiText-2)
python scripts/download_data.py

# ä¸‹è½½æ¨¡å‹ (æ¨è Llama-2-7b)
python scripts/download_from_modelscope.py
```

### 3. è¿è¡Œå‹ç¼©
```bash
# ç¤ºä¾‹ï¼šä½¿ç”¨ GPU è¿è¡Œï¼Œè´å¶æ–¯æœç´¢ 30 æ¬¡ï¼Œå¹¶å¯ç”¨å†è®­ç»ƒ
python main.py --gpu \
  --model_path ./models/Llama-2-7b-hf \
  --strategy bayesian \
  --n_trials 30 \
  --retrain True
```

## âš™ï¸ å‘½ä»¤è¡Œå‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
| :--- | :--- | :--- |
| `--model_path` | æœ¬åœ°æ¨¡å‹ç›®å½•è·¯å¾„ | `./models/Llama-2-7b-hf` |
| `--data_path` | å¤–éƒ¨æ•°æ®é›†è·¯å¾„ (å¦‚ `test.txt`) | `None` (ä½¿ç”¨å†…ç½®) |
| `--strategy` | æœç´¢ç­–ç•¥: `bayesian`, `grid`, `random` | `bayesian` |
| `--n_trials` | è´å¶æ–¯æœç´¢çš„å°è¯•æ¬¡æ•° | `30` |
| `--retrain` | æ˜¯å¦åœ¨æ··åˆç®¡çº¿ä¸­å¯ç”¨è½»é‡çº§å†è®­ç»ƒ | `True` |
| `--gpu` / `--cpu` | å¼ºåˆ¶ä½¿ç”¨ GPU æˆ– CPU | `cpu` (é™¤éæŒ‡å®š `--gpu`) |
| `--save_to_local` | æ˜¯å¦ä¿å­˜æœ€ç»ˆçš„å‹ç¼©æ¨¡å‹ | `False` |

## ğŸ“‚ é¡¹ç›®ç»“æ„

```text
AutoLLM-Compressor/
â”œâ”€â”€ core/               # æ ¸å¿ƒå¼•æ“ (æœç´¢ã€å‹ç¼©ã€è¯„ä¼°)
â”œâ”€â”€ methods/            # å‹ç¼©ç®—æ³•åº“
â”‚   â”œâ”€â”€ pruning/        # å‰ªæ (éšæœº, L2ç»“æ„åŒ–)
â”‚   â”œâ”€â”€ quantization/   # é‡åŒ– (FP16, INT8-SQ)
â”‚   â””â”€â”€ retraining/     # å†è®­ç»ƒ (CLM Finetuning)
â”œâ”€â”€ utils/              # å·¥å…·ç±» (æ•°æ®åŠ è½½, ç»˜å›¾)
â”œâ”€â”€ scripts/            # ä¸‹è½½è„šæœ¬
â”œâ”€â”€ results/            # è¿è¡Œç»“æœ (æ—¥å¿—, æŠ¥å‘Š, å›¾è¡¨)
â””â”€â”€ main.py             # ä¸»å…¥å£
```

## ğŸ› ï¸ å¦‚ä½•æ‰©å±•æ–°æ–¹æ³•ï¼Ÿ

åªéœ€ä¸‰æ­¥å³å¯æ·»åŠ æ–°çš„å‹ç¼©ç®—æ³•ï¼š
1.  åœ¨ `methods/` ä¸‹ç»§æ‰¿ `BaseCompressionMethod` ç±»ã€‚
2.  å®ç° `apply(self, model, **kwargs)` å’Œ `get_info(self)` æ–¹æ³•ã€‚
3.  ä½¿ç”¨ `@register_method("your_method_name")` è£…é¥°å™¨æ³¨å†Œã€‚
4.  åœ¨å¯¹åº”çš„ `__init__.py` ä¸­å¯¼å…¥å³å¯ã€‚

---
ç»´æŠ¤è€…ï¼šCompactMind Team
